{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3 (ipykernel)",
   "language": "python"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "metadata": {
    "id": "J2tNWh6XRcKy"
   },
   "cell_type": "markdown",
   "source": [
    "# Data Analysis and Machine Learning on Crime Data\n",
    "\n",
    "This notebook performs data analysis and machine learning on crime data. It includes data import, visualization, preprocessing, and model training."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Install Required Libraries"
  },
  {
   "metadata": {
    "id": "ot_AtKRZJ4vQ"
   },
   "cell_type": "code",
   "source": [
    "is_upgrade_pip: bool = False\n",
    "\n",
    "\n",
    "def upgrade_pip():\n",
    "    !pip install --upgrade pip > /dev/null\n",
    "    global is_upgrade_pip\n",
    "    is_upgrade_pip = True\n",
    "\n",
    "\n",
    "try:\n",
    "    import pandas as pd\n",
    "except Exception as e:\n",
    "    if not is_upgrade_pip:\n",
    "        upgrade_pip()\n",
    "    !pip install pandas > /dev/null\n",
    "try:\n",
    "    import plotly\n",
    "except Exception as e:\n",
    "    if not is_upgrade_pip:\n",
    "        upgrade_pip()\n",
    "    !pip install plotly > /dev/null\n",
    "try:\n",
    "    import category_encoders\n",
    "except Exception as e:\n",
    "    if not is_upgrade_pip:\n",
    "        upgrade_pip()\n",
    "    !pip install category_encoders > /dev/null\n",
    "try:\n",
    "    import sklearn\n",
    "except Exception as e:\n",
    "    if not is_upgrade_pip:\n",
    "        upgrade_pip()\n",
    "    !pip install sklearn > /dev/null\n",
    "try:\n",
    "    import matplotlib\n",
    "except Exception as e:\n",
    "    if not is_upgrade_pip:\n",
    "        upgrade_pip()\n",
    "    !pip install matplotlib > /dev/null"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Import Libraries"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "import warnings\n",
    "from collections import Counter\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "from category_encoders import OrdinalEncoder\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Define Functions"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def import_csv(file_path):\n",
    "    \"\"\"Import a CSV file and return a pandas DataFrame.\"\"\"\n",
    "    try:\n",
    "        return pd.read_csv(file_path)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File '{file_path}' not found.\")\n",
    "    except pd.errors.EmptyDataError:\n",
    "        print(\"Error: File is empty.\")\n",
    "    except pd.errors.ParserError:\n",
    "        print(\"Error: Parsing issue in the file.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Unexpected error: {e}\")\n",
    "\n",
    "\n",
    "def create_file_path(*path_segments):\n",
    "    \"\"\"Create a file path from path segments.\"\"\"\n",
    "    return os.path.join(*path_segments)\n",
    "\n",
    "\n",
    "def graphpoint(datas, x, y, color):\n",
    "    \"\"\"Display a scatter plot.\"\"\"\n",
    "    fig = px.scatter(datas, x=x, y=y, color=color)\n",
    "    fig.show()\n",
    "\n",
    "\n",
    "def graphbox(datas):\n",
    "    \"\"\"Display a box plot.\"\"\"\n",
    "    datas.plot.box()\n",
    "\n",
    "\n",
    "def graphhistogram(datas, x, color):\n",
    "    \"\"\"Return a histogram plot.\"\"\"\n",
    "    return px.histogram(datas, x=x, color=color)\n",
    "\n",
    "\n",
    "def datasprint(datas, describe, head):\n",
    "    \"\"\"Print data description and head.\"\"\"\n",
    "    if describe:\n",
    "        print(datas.describe())\n",
    "    if head:\n",
    "        print(datas.head())"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Load CSV Files"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "directory = './DataSet'\n",
    "file_path = create_file_path(directory, \"test.csv\")\n",
    "file_path2 = create_file_path(directory, \"train.csv\")\n",
    "\n",
    "df_test = import_csv(file_path)\n",
    "df_train = import_csv(file_path2)\n",
    "\n",
    "if df_test is None or df_train is None:\n",
    "    raise Exception(\"One of the dataframes is empty\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Display Data"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(f\"{file_path} :\")\n",
    "datasprint(df_test, describe=True, head=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(f\"{file_path2} :\")\n",
    "datasprint(df_train, describe=True, head=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Étude des données\n",
    "\n",
    "> Regarder la donnée en fonction de la résolution\n",
    "\n",
    "Nous allons regarder les données en fonction de la résolution pour voir si nous pouvons trouver des corrélations. Nous allons afficher des histogrammes pour chaque colonne de données en fonction de la résolution. Cela nous permettra de voir si certaines colonnes ont un impact sur la résolution.\n",
    "\n",
    "Nous avons donc constater le nombre de résolutions par crime et très élévé. Nous avons donc décidé de regrouper les résolutions en 4 catégories:\n",
    "- Arrestation / Poursuites : ARREST, BOOKED, ARREST, CITED, JUVENILE CITED, JUVENILE BOOKED, PROSECUTED FOR LESSER OFFENSE, PROSECUTED BY OUTSIDE AGENCY\n",
    "- Absence de poursuites / Refus / Cas particuliers : COMPLAINANT REFUSES TO PROSECUTE, DISTRICT ATTORNEY REFUSES TO PROSECUTE, NOT PROSECUTED, JUVENILE ADMONISHED, JUVENILE DIVERTED, CLEARED-CONTACT JUVENILE FOR MORE INFO, PSYCHOPATHIC CASE, EXCEPTIONAL CLEARANCE\n",
    "- Localisation / État de la personne : LOCATED, UNFOUNDED\n",
    "- Indépendant (NONE) : NONE"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df_train_columns: list = df_train.columns.tolist()\n",
    "df_train_columns.remove('Category')\n",
    "df_train_columns.remove('Descript')\n",
    "df_train_columns.remove('Resolution')\n",
    "\n",
    "df_train_columns.remove('Address')  # trop disparate pour être utile\n",
    "\n",
    "for column in df_train_columns:\n",
    "    graphhistogram(df_train, column, 'Resolution').show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Data Preprocessing"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Categorize 'Resolution' into broader categories\n",
    "df_train['Categorie'] = ''\n",
    "df_train.loc[df_train['Resolution'].isin(\n",
    "    ['ARREST, BOOKED', 'ARREST, CITED', 'JUVENILE CITED', 'JUVENILE BOOKED', 'PROSECUTED FOR LESSER OFFENSE',\n",
    "     'PROSECUTED BY OUTSIDE AGENCY']), 'Categorie'] = 'Arrestation / Poursuites'\n",
    "df_train.loc[df_train['Resolution'].isin(\n",
    "    ['COMPLAINANT REFUSES TO PROSECUTE', 'DISTRICT ATTORNEY REFUSES TO PROSECUTE', 'NOT PROSECUTED',\n",
    "     'JUVENILE ADMONISHED', 'JUVENILE DIVERTED', 'CLEARED-CONTACT JUVENILE FOR MORE INFO', 'PSYCHOPATHIC CASE',\n",
    "     'EXCEPTIONAL CLEARANCE']), 'Categorie'] = 'Absence de poursuites / Refus / Cas particuliers'\n",
    "df_train.loc[df_train['Resolution'].isin(['LOCATED', 'UNFOUNDED']), 'Categorie'] = 'Localisation / État de la personne'\n",
    "df_train.loc[df_train['Resolution'].isin(['NONE']), 'Categorie'] = 'Indépendant (NONE)'\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Data Visualization\n",
    "\n",
    "> Nous allons afficher les histogrammes pour chaque colonne de données en fonction de la résolution pour visualiser l'impacte de notre choix de catégorisation."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df_train_columns: list = df_train.columns.tolist()\n",
    "df_train_columns.remove('Category')\n",
    "df_train_columns.remove('Descript')\n",
    "df_train_columns.remove('Resolution')\n",
    "df_train_columns.remove('Categorie')\n",
    "\n",
    "df_train_columns.remove('Address')  # trop disparate pour être utile\n",
    "\n",
    "for column in df_train_columns:\n",
    "    graphhistogram(df_train, column, 'Categorie').show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "graphhistogram(df_train, 'Categorie', 'Resolution').show()",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Feature Selection and Encoding\n",
    "\n",
    "> Nous allons sélectionner les colonnes qui nous intéressent pour l'entraînement du modèle. Nous allons également encoder les colonnes catégorielles en valeurs numériques."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df_train_patch = df_train[['Dates', 'Categorie', 'DayOfWeek', 'PdDistrict', 'Address', 'X', 'Y']]\n",
    "df_test_patch = df_test[['Dates', 'DayOfWeek', 'PdDistrict', 'Address', 'X', 'Y']]\n",
    "\n",
    "categorical_features = [col for col in df_train_patch.columns if df_train[col].dtype == 'object']\n",
    "encoder = OrdinalEncoder(cols=categorical_features).fit(df_train_patch)\n",
    "df_train_patch_2 = encoder.transform(df_train_patch)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Sampling and Splitting Data\n",
    "\n",
    "> Nous allons échantillonner les données pour réduire la taille de l'ensemble d'entraînement. Nous allons également diviser les données en ensembles d'entraînement et de test.\n",
    "\n",
    "Nous avons décidé de prendre 25000 échantillons pour chaque catégorie. Le choix de faire un échantillonage est dû à la taille des données qui est très grande. Nous avons donc décidé de prendre un échantillon pour chaque catégorie pour réduire la taille des données. 25000 est un nombre suffisant pour avoir une bonne précision."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "nb = 25000\n",
    "df_train_patch_sample = pd.concat([\n",
    "    df_train_patch_2[df_train_patch_2.Categorie == i].sample(\n",
    "        min(nb, len(df_train_patch_2[df_train_patch_2.Categorie == i])), replace=True)\n",
    "    for i in range(4)\n",
    "])\n",
    "\n",
    "y = df_train_patch_sample.Categorie\n",
    "X = df_train_patch_sample.drop(['Categorie'], axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Model Training and Evaluation\n",
    "\n",
    "> Nous allons entraîner des modèles de classification sur les données d'entraînement et évaluer leur précision sur les données de test.\n",
    "\n",
    "Nous allons entraîner trois modèles de classification différents : Decision Tree, Random Forest et K-Nearest Neighbors.\n",
    "\n",
    "Le choix d'utiliser trois modèles différents est dû à la nature des données. Nous avons des données catégorielles et numériques. Nous avons donc décidé d'utiliser des modèles différents pour voir lequel est le plus performant.\n",
    "\n",
    "Nous ajouter une matrice de confusion pour chaque modèle pour voir les erreurs de classification."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Le modèle Decision Tree a une précision de plus ou moins 55%.\n",
    "\n",
    "Le modèle fait un bon travail pour reconnaître la classe 3, mais il a du mal à bien distinguer les classes 1 et 2, avec environ 50% de précision. Cela signifie qu'il confond souvent ces deux classes, tandis qu'il est plus fiable pour identifier la classe 3."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Decision Tree\n",
    "clf = tree.DecisionTreeClassifier().fit(X_train, y_train)\n",
    "acctree = clf.score(X_test, y_test) * 100\n",
    "y_pred_tree = clf.predict(X_test)\n",
    "print(f'Decision Tree Accuracy: {acctree:.2f}%')\n",
    "print(\"Decision Tree Confusion Matrix:\")\n",
    "cm_tree = confusion_matrix(y_test, y_pred_tree)\n",
    "disp_tree = ConfusionMatrixDisplay(confusion_matrix=cm_tree, display_labels=clf.classes_)\n",
    "disp_tree.plot(cmap=plt.cm.Blues)\n",
    "plt.title('Decision Tree Confusion Matrix')\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Le modèle Random Forest a une précision de plus ou moins 60%.\n",
    "\n",
    "Le modèle fait un bon travail pour reconnaître la classe 3, avec des résultats solides, mais il a plus de difficulté à bien distinguer les classes 1 et 2, où il se trompe environ une fois sur deux. Il confond souvent ces deux classes, tandis qu'il est plus précis pour identifier la classe 3."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Random Forest\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42).fit(X_train, y_train)\n",
    "accrf = accuracy_score(y_test, rf_classifier.predict(X_test)) * 100\n",
    "y_pred_rf = rf_classifier.predict(X_test)\n",
    "print(f'Random Forest Accuracy: {accrf:.2f}%')\n",
    "print(\"Random Forest Confusion Matrix:\")\n",
    "cm_rf = confusion_matrix(y_test, y_pred_rf)\n",
    "disp_rf = ConfusionMatrixDisplay(confusion_matrix=cm_rf, display_labels=rf_classifier.classes_)\n",
    "disp_rf.plot(cmap=plt.cm.Blues)\n",
    "plt.title('Random Forest Confusion Matrix')\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Le modèle K-Nearest Neighbors a une précision de plus ou moins 45%.\n",
    "\n",
    "Le modèle a du mal à distinguer les trois classes. Il fait beaucoup d'erreurs en confondant la classe 1 avec la classe 2 et inversement. Les prédictions pour la classe 3 sont également assez imprécises, montrant que le modèle a des difficultés à bien classifier l'ensemble des classes.\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# K-Nearest Neighbors\n",
    "knn = KNeighborsClassifier(n_neighbors=2).fit(X_train, y_train)\n",
    "accknn = accuracy_score(y_test, knn.predict(X_test)) * 100\n",
    "y_pred_knn = knn.predict(X_test)\n",
    "print(f'KNN Accuracy: {accknn:.2f}%')\n",
    "print(\"KNN Confusion Matrix:\")\n",
    "cm_knn = confusion_matrix(y_test, y_pred_knn)\n",
    "disp_knn = ConfusionMatrixDisplay(confusion_matrix=cm_knn, display_labels=knn.classes_)\n",
    "disp_knn.plot(cmap=plt.cm.Blues)\n",
    "plt.title('KNN Confusion Matrix')\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## KNeighborsClassifier - Choosing the Best K Value\n",
    "\n",
    "> Nous allons choisir la meilleure valeur de k pour le modèle K-Nearest Neighbors en traçant l'exactitude en fonction de différentes valeurs de k.\n",
    "\n",
    "Nous avons décidé de choisir la valeur de k qui donne la meilleure précision pour le modèle K-Nearest Neighbors.\n",
    "\n",
    "On remarque que la précision est maximale pour k=2."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "k_values = range(1, 21)\n",
    "accuracies = []\n",
    "for k in k_values:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X_train, y_train)\n",
    "    y_pred = knn.predict(X_test)\n",
    "    accuracies.append(accuracy_score(y_test, y_pred))\n",
    "plt.plot(k_values, accuracies)\n",
    "plt.xlabel('Number of Neighbors (k)')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy for different k values')\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Overall Accuracy"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(\"Overall Accuracy\")\n",
    "print(f'Decision Tree: {acctree:.2f}%')\n",
    "print(f'Random Forest: {accrf:.2f}%')\n",
    "print(f'KNN: {accknn:.2f}%')\n",
    "glbacc = (acctree + accrf + accknn) / 3\n",
    "print(f'Global: {glbacc:.2f}%')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Predict New Data"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "warnings.filterwarnings(\"ignore\", category=FutureWarning, message=\".*Downcasting object dtype arrays on .fillna.*\")\n",
    "\n",
    "new_data = {\n",
    "    \"Dates\": [\"2015-05-10 23:59:00\"],\n",
    "    \"DayOfWeek\": [\"Sunday\"],\n",
    "    \"PdDistrict\": [\"BAYVIEW\"],\n",
    "    \"Address\": [\"2000 Block of THOMAS AV\"],\n",
    "    \"X\": [-122.39958770418998],\n",
    "    \"Y\": [37.7350510103906],\n",
    "    \"Categorie\": [None]\n",
    "}\n",
    "\n",
    "new_df = pd.DataFrame(new_data)\n",
    "new_df_encoded = encoder.transform(new_df).drop(columns=['Categorie'])\n",
    "\n",
    "tree_prediction = clf.predict(new_df_encoded)\n",
    "rf_prediction = rf_classifier.predict(new_df_encoded)\n",
    "knn_prediction = knn.predict(new_df_encoded)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Final Prediction Using Majority Vote"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "predictions = [tuple(tree_prediction), tuple(rf_prediction), tuple(knn_prediction)]\n",
    "prediction_counts = Counter(predictions)\n",
    "most_common_prediction, count = prediction_counts.most_common(1)[0]\n",
    "\n",
    "if count == 1:\n",
    "    accuracies = {'tree': acctree, 'rf': accrf, 'knn': accknn}\n",
    "    most_accurate_model = max(accuracies, key=accuracies.get)\n",
    "    final_prediction = eval(f'{most_accurate_model}_prediction')\n",
    "else:\n",
    "    final_prediction = most_common_prediction\n",
    "\n",
    "final_prediction = int(final_prediction[0])\n",
    "print(f\"Final Prediction: {final_prediction}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Map Prediction to Category"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "prediction_mapping = {\n",
    "    0: 'Arrestation / Poursuites',\n",
    "    1: 'Absence de poursuites / Refus / Cas particuliers',\n",
    "    2: 'Localisation / État de la personne',\n",
    "    3: 'Indépendant (NONE)'\n",
    "}\n",
    "\n",
    "final_prediction_text = prediction_mapping.get(final_prediction, \"Catégorie inconnue\")\n",
    "print(f\"Final Prediction: {final_prediction_text}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Aprés avoir fait l'analyse des données\n",
    "\n",
    "> Non implémenté\n",
    "\n",
    "Nous avons décidé de spliter la date dans le but de préciser les décisions prises en fonction des Date ou de l'horraire\n",
    "- création de la colonne 'Date'\n",
    "- création de la colonne 'Heure'\n",
    "- création de la colonne 'MonthofYear'"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df_train['Date'] = pd.to_datetime(df_train['Dates']).dt.date\n",
    "df_train['Heure'] = pd.to_datetime(df_train['Dates']).dt.time\n",
    "df_train['MonthofYear'] = pd.to_datetime(df_train['Date']).dt.month\n",
    "\n",
    "# print(df_train)\n",
    "\n",
    "df_test['Date'] = pd.to_datetime(df_test['Dates']).dt.date\n",
    "df_test['Heure'] = pd.to_datetime(df_test['Dates']).dt.time\n",
    "df_test['MonthofYear'] = pd.to_datetime(df_test['Date']).dt.month\n",
    "\n",
    "# print(df_test)\n",
    "\n",
    "df_train_patch = df_train[\n",
    "    ['Dates', 'Categorie', 'DayOfWeek', 'PdDistrict', 'Address', 'X', 'Y', 'Date', 'Heure', 'MonthofYear']]\n",
    "df_test_patch = df_test[['Dates', 'DayOfWeek', 'PdDistrict', 'Address', 'X', 'Y', 'Date', 'Heure', 'MonthofYear']]\n",
    "\n",
    "categorical_features = [col for col in df_train_patch.columns if df_train[col].dtype == 'object']\n",
    "encoder = OrdinalEncoder(cols=categorical_features).fit(df_train_patch)\n",
    "df_train_patch_2 = encoder.transform(df_train_patch)\n",
    "\n",
    "nb = 25000\n",
    "df_train_patch_sample = pd.concat([\n",
    "    df_train_patch_2[df_train_patch_2.Categorie == i].sample(\n",
    "        min(nb, len(df_train_patch_2[df_train_patch_2.Categorie == i])), replace=True)\n",
    "    for i in range(4)\n",
    "])\n",
    "\n",
    "y = df_train_patch_sample.Categorie\n",
    "X = df_train_patch_sample.drop(['Categorie'], axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Le modèle Decision Tree a une précision de plus ou moins 55%.\n",
    "\n",
    "Le modèle est assez performant pour reconnaître la classe 3, avec une bonne précision, mais il rencontre des difficultés à distinguer entre les classes 1 et 2, avec de nombreuses confusions. Cela indique qu'il y a un besoin d'amélioration pour mieux classifier les classes 1 et 2, tandis que la classe 3 est identifiée de manière plus fiable."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Decision Tree\n",
    "clf = tree.DecisionTreeClassifier().fit(X_train, y_train)\n",
    "acctree = clf.score(X_test, y_test) * 100\n",
    "y_pred_tree = clf.predict(X_test)\n",
    "print(f'Decision Tree Accuracy: {acctree:.2f}%')\n",
    "print(\"Decision Tree Confusion Matrix:\")\n",
    "cm_tree = confusion_matrix(y_test, y_pred_tree)\n",
    "disp_tree = ConfusionMatrixDisplay(confusion_matrix=cm_tree, display_labels=clf.classes_)\n",
    "disp_tree.plot(cmap=plt.cm.Blues)\n",
    "plt.title('Decision Tree Confusion Matrix')\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Le modèle Random Forest a une précision de plus ou moins 65%.\n",
    "\n",
    "Le modèle est très performant, surtout pour la classe 2, qu'il identifie avec une bonne précision. Cependant, il a encore quelques difficultés à distinguer les classes 1 et 3, mais globalement, il fait un bon travail dans la classification des trois classes.\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Random Forest\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42).fit(X_train, y_train)\n",
    "accrf = accuracy_score(y_test, rf_classifier.predict(X_test)) * 100\n",
    "y_pred_rf = rf_classifier.predict(X_test)\n",
    "print(f'Random Forest Accuracy: {accrf:.2f}%')\n",
    "print(\"Random Forest Confusion Matrix:\")\n",
    "cm_rf = confusion_matrix(y_test, y_pred_rf)\n",
    "disp_rf = ConfusionMatrixDisplay(confusion_matrix=cm_rf, display_labels=rf_classifier.classes_)\n",
    "disp_rf.plot(cmap=plt.cm.Blues)\n",
    "plt.title('Random Forest Confusion Matrix')\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Le modèle K-Nearest Neighbors a une précision de plus ou moins 47%.\n",
    "\n",
    "Le modèle montre de bonnes performances, particulièrement pour la classe 2, mais il a du mal à distinguer les classes 1 et 3, avec un nombre significatif d'erreurs. Cela suggère qu'il nécessite des améliorations pour mieux classifier les classes 1 et 3 tout en continuant à bien identifier la classe 2."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# K-Nearest Neighbors\n",
    "knn = KNeighborsClassifier(n_neighbors=2).fit(X_train, y_train)\n",
    "accknn = accuracy_score(y_test, knn.predict(X_test)) * 100\n",
    "y_pred_knn = knn.predict(X_test)\n",
    "print(f'KNN Accuracy: {accknn:.2f}%')\n",
    "print(\"KNN Confusion Matrix:\")\n",
    "cm_knn = confusion_matrix(y_test, y_pred_knn)\n",
    "disp_knn = ConfusionMatrixDisplay(confusion_matrix=cm_knn, display_labels=knn.classes_)\n",
    "disp_knn.plot(cmap=plt.cm.Blues)\n",
    "plt.title('KNN Confusion Matrix')\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(\"Overall Accuracy\")\n",
    "print(f'Decision Tree: {acctree:.2f}%')\n",
    "print(f'Random Forest: {accrf:.2f}%')\n",
    "print(f'KNN: {accknn:.2f}%')\n",
    "glbacc = (acctree + accrf + accknn) / 3\n",
    "print(f'Global: {glbacc:.2f}%')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "warnings.filterwarnings(\"ignore\", category=FutureWarning, message=\".*Downcasting object dtype arrays on .fillna.*\")\n",
    "\n",
    "new_data = {\n",
    "    \"Dates\": [\"2015-05-10 23:59:00\"],\n",
    "    \"DayOfWeek\": [\"Sunday\"],\n",
    "    \"PdDistrict\": [\"BAYVIEW\"],\n",
    "    \"Address\": [\"2000 Block of THOMAS AV\"],\n",
    "    \"X\": [-122.39958770418998],\n",
    "    \"Y\": [37.7350510103906],\n",
    "    \"Categorie\": [None],\n",
    "    \"Date\": [pd.to_datetime(\"2015-05-10 23:59:00\").date()],\n",
    "    \"Heure\": [pd.to_datetime(\"2015-05-10 23:59:00\").time()],\n",
    "    \"MonthofYear\": [pd.to_datetime(\"2015-05-10 23:59:00\").month]\n",
    "}\n",
    "\n",
    "new_df = pd.DataFrame(new_data)\n",
    "new_df_encoded = encoder.transform(new_df).drop(columns=['Categorie'])\n",
    "\n",
    "tree_prediction = clf.predict(new_df_encoded)\n",
    "rf_prediction = rf_classifier.predict(new_df_encoded)\n",
    "knn_prediction = knn.predict(new_df_encoded)\n",
    "\n",
    "predictions = [tuple(tree_prediction), tuple(rf_prediction), tuple(knn_prediction)]\n",
    "prediction_counts = Counter(predictions)\n",
    "most_common_prediction, count = prediction_counts.most_common(1)[0]\n",
    "\n",
    "if count == 1:\n",
    "    accuracies = {'tree': acctree, 'rf': accrf, 'knn': accknn}\n",
    "    most_accurate_model = max(accuracies, key=accuracies.get)\n",
    "    final_prediction = eval(f'{most_accurate_model}_prediction')\n",
    "else:\n",
    "    final_prediction = most_common_prediction\n",
    "\n",
    "final_prediction = int(final_prediction[0])\n",
    "print(f\"Final Prediction: {final_prediction}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "prediction_mapping = {\n",
    "    0: 'Arrestation / Poursuites',\n",
    "    1: 'Absence de poursuites / Refus / Cas particuliers',\n",
    "    2: 'Localisation / État de la personne',\n",
    "    3: 'Indépendant (NONE)'\n",
    "}\n",
    "\n",
    "final_prediction_text = prediction_mapping.get(final_prediction, \"Catégorie inconnue\")\n",
    "print(f\"Final Prediction: {final_prediction_text}\")"
   ],
   "outputs": [],
   "execution_count": null
  }
 ]
}
