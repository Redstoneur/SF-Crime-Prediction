{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3 (ipykernel)",
   "language": "python"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Data Analysis and Machine Learning on Crime Data\n",
    "\n",
    "This notebook performs data analysis and machine learning on crime data. It includes data import, visualization, preprocessing, and model training."
   ],
   "metadata": {
    "id": "J2tNWh6XRcKy"
   }
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Install Required Libraries"
  },
  {
   "cell_type": "code",
   "source": [
    "try :\n",
    "    import pandas as pd\n",
    "except Exception as e:\n",
    "    !pip install pandas > /dev/null\n",
    "try:\n",
    "    import plotly\n",
    "except Exception as e:\n",
    "    !pip install plotly > /dev/null\n",
    "try:\n",
    "    import category_encoders\n",
    "except Exception as e:\n",
    "    !pip install category_encoders > /dev/null\n",
    "try:\n",
    "    import sklearn\n",
    "except Exception as e:\n",
    "    !pip install sklearn > /dev/null\n",
    "try:\n",
    "    import matplotlib\n",
    "except Exception as e:\n",
    "    !pip install matplotlib > /dev/null"
   ],
   "metadata": {
    "id": "ot_AtKRZJ4vQ",
    "ExecuteTime": {
     "end_time": "2024-10-01T08:35:07.546001Z",
     "start_time": "2024-10-01T08:35:07.533742Z"
    }
   },
   "outputs": [],
   "execution_count": 44
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Import Libraries"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-01T08:35:07.593171Z",
     "start_time": "2024-10-01T08:35:07.583174Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import plotly.express as px\n",
    "from category_encoders import OrdinalEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from collections import Counter"
   ],
   "outputs": [],
   "execution_count": 45
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Define Functions"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-01T08:35:07.701998Z",
     "start_time": "2024-10-01T08:35:07.688013Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def import_csv(file_path):\n",
    "    \"\"\"Import a CSV file and return a pandas DataFrame.\"\"\"\n",
    "    try:\n",
    "        return pd.read_csv(file_path)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File '{file_path}' not found.\")\n",
    "    except pd.errors.EmptyDataError:\n",
    "        print(\"Error: File is empty.\")\n",
    "    except pd.errors.ParserError:\n",
    "        print(\"Error: Parsing issue in the file.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Unexpected error: {e}\")\n",
    "\n",
    "def create_file_path(*path_segments):\n",
    "    \"\"\"Create a file path from path segments.\"\"\"\n",
    "    return os.path.join(*path_segments)\n",
    "\n",
    "def graphpoint(datas, x, y, color):\n",
    "    \"\"\"Display a scatter plot.\"\"\"\n",
    "    fig = px.scatter(datas, x=x, y=y, color=color)\n",
    "    fig.show()\n",
    "\n",
    "def graphbox(datas):\n",
    "    \"\"\"Display a box plot.\"\"\"\n",
    "    datas.plot.box()\n",
    "\n",
    "def graphhistogram(datas, x, color):\n",
    "    \"\"\"Return a histogram plot.\"\"\"\n",
    "    return px.histogram(datas, x=x, color=color)\n",
    "\n",
    "def datasprint(datas, describe, head):\n",
    "    \"\"\"Print data description and head.\"\"\"\n",
    "    if describe:\n",
    "        print(datas.describe())\n",
    "    if head:\n",
    "        print(datas.head())"
   ],
   "outputs": [],
   "execution_count": 46
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Load CSV Files"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-01T08:35:09.953743Z",
     "start_time": "2024-10-01T08:35:07.782403Z"
    }
   },
   "cell_type": "code",
   "source": [
    "directory = './DataSet'\n",
    "file_path = create_file_path(directory, \"test.csv\")\n",
    "file_path2 = create_file_path(directory, \"train.csv\")\n",
    "\n",
    "df_test = import_csv(file_path)\n",
    "df_train = import_csv(file_path2)\n",
    "\n",
    "if df_test is None or df_train is None:\n",
    "    raise Exception(\"One of the dataframes is empty\")\n"
   ],
   "outputs": [],
   "execution_count": 47
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Display Data"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-01T08:35:10.140860Z",
     "start_time": "2024-10-01T08:35:10.033279Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(f\"{file_path} :\")\n",
    "datasprint(df_test, describe=True, head=True)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./DataSet\\test.csv :\n",
      "                  Id              X              Y\n",
      "count  884262.000000  884262.000000  884262.000000\n",
      "mean   442130.500000    -122.422693      37.771476\n",
      "std    255264.596205       0.030985       0.484824\n",
      "min         0.000000    -122.513642      37.707879\n",
      "25%    221065.250000    -122.433069      37.752374\n",
      "50%    442130.500000    -122.416517      37.775421\n",
      "75%    663195.750000    -122.406959      37.784353\n",
      "max    884261.000000    -120.500000      90.000000\n",
      "   Id                Dates DayOfWeek PdDistrict                   Address  \\\n",
      "0   0  2015-05-10 23:59:00    Sunday    BAYVIEW   2000 Block of THOMAS AV   \n",
      "1   1  2015-05-10 23:51:00    Sunday    BAYVIEW        3RD ST / REVERE AV   \n",
      "2   2  2015-05-10 23:50:00    Sunday   NORTHERN    2000 Block of GOUGH ST   \n",
      "3   3  2015-05-10 23:45:00    Sunday  INGLESIDE  4700 Block of MISSION ST   \n",
      "4   4  2015-05-10 23:45:00    Sunday  INGLESIDE  4700 Block of MISSION ST   \n",
      "\n",
      "            X          Y  \n",
      "0 -122.399588  37.735051  \n",
      "1 -122.391523  37.732432  \n",
      "2 -122.426002  37.792212  \n",
      "3 -122.437394  37.721412  \n",
      "4 -122.437394  37.721412  \n"
     ]
    }
   ],
   "execution_count": 48
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-01T08:35:10.311074Z",
     "start_time": "2024-10-01T08:35:10.221340Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(f\"{file_path2} :\")\n",
    "datasprint(df_train, describe=True, head=True)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./DataSet\\train.csv :\n",
      "                   X              Y\n",
      "count  878049.000000  878049.000000\n",
      "mean     -122.422616      37.771020\n",
      "std         0.030354       0.456893\n",
      "min      -122.513642      37.707879\n",
      "25%      -122.432952      37.752427\n",
      "50%      -122.416420      37.775421\n",
      "75%      -122.406959      37.784369\n",
      "max      -120.500000      90.000000\n",
      "                 Dates        Category                      Descript  \\\n",
      "0  2015-05-13 23:53:00        WARRANTS                WARRANT ARREST   \n",
      "1  2015-05-13 23:53:00  OTHER OFFENSES      TRAFFIC VIOLATION ARREST   \n",
      "2  2015-05-13 23:33:00  OTHER OFFENSES      TRAFFIC VIOLATION ARREST   \n",
      "3  2015-05-13 23:30:00   LARCENY/THEFT  GRAND THEFT FROM LOCKED AUTO   \n",
      "4  2015-05-13 23:30:00   LARCENY/THEFT  GRAND THEFT FROM LOCKED AUTO   \n",
      "\n",
      "   DayOfWeek PdDistrict      Resolution                    Address  \\\n",
      "0  Wednesday   NORTHERN  ARREST, BOOKED         OAK ST / LAGUNA ST   \n",
      "1  Wednesday   NORTHERN  ARREST, BOOKED         OAK ST / LAGUNA ST   \n",
      "2  Wednesday   NORTHERN  ARREST, BOOKED  VANNESS AV / GREENWICH ST   \n",
      "3  Wednesday   NORTHERN            NONE   1500 Block of LOMBARD ST   \n",
      "4  Wednesday       PARK            NONE  100 Block of BRODERICK ST   \n",
      "\n",
      "            X          Y  \n",
      "0 -122.425892  37.774599  \n",
      "1 -122.425892  37.774599  \n",
      "2 -122.424363  37.800414  \n",
      "3 -122.426995  37.800873  \n",
      "4 -122.438738  37.771541  \n"
     ]
    }
   ],
   "execution_count": 49
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Étude des données\n",
    "\n",
    "> Regarder la donnée en fonction de la résolution\n",
    "\n",
    "Nous allons regarder les données en fonction de la résolution pour voir si nous pouvons trouver des corrélations. Nous allons afficher des histogrammes pour chaque colonne de données en fonction de la résolution. Cela nous permettra de voir si certaines colonnes ont un impact sur la résolution.\n",
    "\n",
    "Nous avons donc constater le nombre de résolutions par crime et très élévé. Nous avons donc décidé de regrouper les résolutions en 4 catégories:\n",
    "- Arrestation / Poursuites : ARREST, BOOKED, ARREST, CITED, JUVENILE CITED, JUVENILE BOOKED, PROSECUTED FOR LESSER OFFENSE, PROSECUTED BY OUTSIDE AGENCY\n",
    "- Absence de poursuites / Refus / Cas particuliers : COMPLAINANT REFUSES TO PROSECUTE, DISTRICT ATTORNEY REFUSES TO PROSECUTE, NOT PROSECUTED, JUVENILE ADMONISHED, JUVENILE DIVERTED, CLEARED-CONTACT JUVENILE FOR MORE INFO, PSYCHOPATHIC CASE, EXCEPTIONAL CLEARANCE\n",
    "- Localisation / État de la personne : LOCATED, UNFOUNDED\n",
    "- Indépendant (NONE) : NONE"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-01T08:35:10.403111Z",
     "start_time": "2024-10-01T08:35:10.388910Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# df_train_columns: list = df_train.columns.tolist()\n",
    "# df_train_columns.remove('Category')\n",
    "# df_train_columns.remove('Descript')\n",
    "# df_train_columns.remove('Resolution')\n",
    "# \n",
    "# for column in df_train_columns:\n",
    "#     graphhistogram(df_train, column, 'Resolution').show()"
   ],
   "outputs": [],
   "execution_count": 50
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Data Preprocessing"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-01T08:35:10.605859Z",
     "start_time": "2024-10-01T08:35:10.483860Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Categorize 'Resolution' into broader categories\n",
    "df_train['Categorie'] = ''\n",
    "df_train.loc[df_train['Resolution'].isin(['ARREST, BOOKED', 'ARREST, CITED', 'JUVENILE CITED', 'JUVENILE BOOKED', 'PROSECUTED FOR LESSER OFFENSE', 'PROSECUTED BY OUTSIDE AGENCY']), 'Categorie'] = 'Arrestation / Poursuites'\n",
    "df_train.loc[df_train['Resolution'].isin(['COMPLAINANT REFUSES TO PROSECUTE', 'DISTRICT ATTORNEY REFUSES TO PROSECUTE', 'NOT PROSECUTED', 'JUVENILE ADMONISHED', 'JUVENILE DIVERTED', 'CLEARED-CONTACT JUVENILE FOR MORE INFO', 'PSYCHOPATHIC CASE', 'EXCEPTIONAL CLEARANCE']), 'Categorie'] = 'Absence de poursuites / Refus / Cas particuliers'\n",
    "df_train.loc[df_train['Resolution'].isin(['LOCATED', 'UNFOUNDED']), 'Categorie'] = 'Localisation / État de la personne'\n",
    "df_train.loc[df_train['Resolution'].isin(['NONE']), 'Categorie'] = 'Indépendant (NONE)'\n"
   ],
   "outputs": [],
   "execution_count": 51
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Data Visualization\n",
    "\n",
    "> Nous allons afficher les histogrammes pour chaque colonne de données en fonction de la résolution pour visualiser l'impacte de notre choix de catégorisation."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-01T08:35:10.698411Z",
     "start_time": "2024-10-01T08:35:10.685132Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# df_train_columns: list = df_train.columns.tolist()\n",
    "# df_train_columns.remove('Category')\n",
    "# df_train_columns.remove('Descript')\n",
    "# df_train_columns.remove('Resolution')\n",
    "# \n",
    "# for column in df_train_columns:\n",
    "#     graphhistogram(df_train, column, 'Resolution').show()"
   ],
   "outputs": [],
   "execution_count": 52
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Feature Selection and Encoding\n",
    "\n",
    "> Nous allons sélectionner les colonnes qui nous intéressent pour l'entraînement du modèle. Nous allons également encoder les colonnes catégorielles en valeurs numériques."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-01T08:35:13.221211Z",
     "start_time": "2024-10-01T08:35:10.777927Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_train_patch = df_train[['Dates', 'Categorie', 'DayOfWeek', 'PdDistrict', 'Address', 'X', 'Y']]\n",
    "df_test_patch = df_test[['Dates', 'DayOfWeek', 'PdDistrict', 'Address', 'X', 'Y']]\n",
    "\n",
    "categorical_features = [col for col in df_train_patch.columns if df_train[col].dtype == 'object']\n",
    "encoder = OrdinalEncoder(cols=categorical_features).fit(df_train_patch)\n",
    "df_train_patch_2 = encoder.transform(df_train_patch)\n"
   ],
   "outputs": [],
   "execution_count": 53
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Sampling and Splitting Data\n",
    "\n",
    "> Nous allons échantillonner les données pour réduire la taille de l'ensemble d'entraînement. Nous allons également diviser les données en ensembles d'entraînement et de test.\n",
    "\n",
    "Nous avons décidé de prendre 25000 échantillons pour chaque catégorie. Le choix de faire un échantillonage est dû à la taille des données qui est très grande. Nous avons donc décidé de prendre un échantillon pour chaque catégorie pour réduire la taille des données. 25000 est un nombre suffisant pour avoir une bonne précision."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-01T08:35:13.437343Z",
     "start_time": "2024-10-01T08:35:13.285186Z"
    }
   },
   "cell_type": "code",
   "source": [
    "nb = 25000\n",
    "df_train_patch_sample = pd.concat([\n",
    "    df_train_patch_2[df_train_patch_2.Categorie == i].sample(min(nb, len(df_train_patch_2[df_train_patch_2.Categorie == i])), replace=True) \n",
    "    for i in range(4)\n",
    "])\n",
    "\n",
    "y = df_train_patch_sample.Categorie\n",
    "X = df_train_patch_sample.drop(['Categorie'], axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ],
   "outputs": [],
   "execution_count": 54
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Model Training and Evaluation\n",
    "\n",
    "> Nous allons entraîner des modèles de classification sur les données d'entraînement et évaluer leur précision sur les données de test.\n",
    "\n",
    "Nous allons entraîner trois modèles de classification différents : Decision Tree, Random Forest et K-Nearest Neighbors.\n",
    "\n",
    "Le choix d'utiliser trois modèles différents est dû à la nature des données. Nous avons des données catégorielles et numériques. Nous avons donc décidé d'utiliser des modèles différents pour voir lequel est le plus performant."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-01T08:35:24.213876Z",
     "start_time": "2024-10-01T08:35:13.501153Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Decision Tree\n",
    "clf = tree.DecisionTreeClassifier().fit(X_train, y_train)\n",
    "acctree = clf.score(X_test, y_test) * 100\n",
    "print(f'Decision Tree Accuracy: {acctree:.2f}%')\n",
    "\n",
    "# Random Forest\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42).fit(X_train, y_train)\n",
    "accrf = accuracy_score(y_test, rf_classifier.predict(X_test)) * 100\n",
    "print(f'Random Forest Accuracy: {accrf:.2f}%')\n",
    "\n",
    "# K-Nearest Neighbors\n",
    "knn = KNeighborsClassifier(n_neighbors=2).fit(X_train, y_train)\n",
    "accknn = accuracy_score(y_test, knn.predict(X_test)) * 100\n",
    "print(f'KNN Accuracy: {accknn:.2f}%')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Accuracy: 56.05%\n",
      "Random Forest Accuracy: 60.41%\n",
      "KNN Accuracy: 44.34%\n"
     ]
    }
   ],
   "execution_count": 55
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## KNeighborsClassifier - Choosing the Best K Value\n",
    "\n",
    "> Nous allons choisir la meilleure valeur de k pour le modèle K-Nearest Neighbors en traçant l'exactitude en fonction de différentes valeurs de k.\n",
    "\n",
    "Nous avons décidé de choisir la valeur de k qui donne la meilleure précision pour le modèle K-Nearest Neighbors.\n",
    "\n",
    "On remarque que la précision est maximale pour k=2."
   ]
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2024-10-01T08:35:24.277687Z"
    }
   },
   "cell_type": "code",
   "source": [
    "k_values = range(1, 21)\n",
    "accuracies = []\n",
    "for k in k_values:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X_train, y_train)\n",
    "    y_pred = knn.predict(X_test)\n",
    "    accuracies.append(accuracy_score(y_test, y_pred))\n",
    "plt.plot(k_values, accuracies)\n",
    "plt.xlabel('Number of Neighbors (k)')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy for different k values')\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Overall Accuracy"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-01T08:17:35.538224Z",
     "start_time": "2024-10-01T08:17:35.524353Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"Overall Accuracy\")\n",
    "print(f'Decision Tree: {acctree:.2f}%')\n",
    "print(f'Random Forest: {accrf:.2f}%')\n",
    "print(f'KNN: {accknn:.2f}%')\n",
    "glbacc = (acctree + accrf + accknn) / 3\n",
    "print(f'Global: {glbacc:.2f}%')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Accuracy\n",
      "Decision Tree: 55.69%\n",
      "Random Forest: 60.17%\n",
      "KNN: 45.00%\n",
      "Global: 53.62%\n"
     ]
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Predict New Data"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-01T08:17:35.648265Z",
     "start_time": "2024-10-01T08:17:35.620062Z"
    }
   },
   "cell_type": "code",
   "source": [
    "warnings.filterwarnings(\"ignore\", category=FutureWarning, message=\".*Downcasting object dtype arrays on .fillna.*\")\n",
    "\n",
    "new_data = {\n",
    "    \"Dates\": [\"2015-05-10 23:59:00\"],\n",
    "    \"DayOfWeek\": [\"Sunday\"],\n",
    "    \"PdDistrict\": [\"BAYVIEW\"],\n",
    "    \"Address\": [\"2000 Block of THOMAS AV\"],\n",
    "    \"X\": [-122.39958770418998],\n",
    "    \"Y\": [37.7350510103906],\n",
    "    \"Categorie\": [None]\n",
    "}\n",
    "\n",
    "new_df = pd.DataFrame(new_data)\n",
    "new_df_encoded = encoder.transform(new_df).drop(columns=['Categorie'])\n",
    "\n",
    "tree_prediction = clf.predict(new_df_encoded)\n",
    "rf_prediction = rf_classifier.predict(new_df_encoded)\n",
    "knn_prediction = knn.predict(new_df_encoded)"
   ],
   "outputs": [],
   "execution_count": 33
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Final Prediction Using Majority Vote"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-01T08:17:35.724749Z",
     "start_time": "2024-10-01T08:17:35.711584Z"
    }
   },
   "cell_type": "code",
   "source": [
    "predictions = [tuple(tree_prediction), tuple(rf_prediction), tuple(knn_prediction)]\n",
    "prediction_counts = Counter(predictions)\n",
    "most_common_prediction, count = prediction_counts.most_common(1)[0]\n",
    "\n",
    "if count == 1:\n",
    "    accuracies = {'tree': acctree, 'rf': accrf, 'knn': accknn}\n",
    "    most_accurate_model = max(accuracies, key=accuracies.get)\n",
    "    final_prediction = eval(f'{most_accurate_model}_prediction')\n",
    "else:\n",
    "    final_prediction = most_common_prediction\n",
    "\n",
    "final_prediction = int(final_prediction[0])\n",
    "print(f\"Final Prediction: {final_prediction}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Prediction: 2\n"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Map Prediction to Category"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-01T08:17:35.801486Z",
     "start_time": "2024-10-01T08:17:35.787342Z"
    }
   },
   "cell_type": "code",
   "source": [
    "prediction_mapping = {\n",
    "    0: 'Arrestation / Poursuites',\n",
    "    1: 'Absence de poursuites / Refus / Cas particuliers',\n",
    "    2: 'Localisation / État de la personne',\n",
    "    3: 'Indépendant (NONE)'\n",
    "}\n",
    "\n",
    "final_prediction_text = prediction_mapping.get(final_prediction, \"Catégorie inconnue\")\n",
    "print(f\"Final Prediction: {final_prediction_text}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Prediction: Localisation / État de la personne\n"
     ]
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Aprés avoir fait l'analyse des données\n",
    "\n",
    "> Non implémenté\n",
    "\n",
    "Nous avons décidé de spliter la date dans le but de préciser les décisions prises en fonction des Date ou de l'horraire\n",
    "- création de la colonne 'Date'\n",
    "- création de la colonne 'Heure'\n",
    "- création de la colonne 'MonthofYear'"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-01T08:29:15.832888Z",
     "start_time": "2024-10-01T08:29:11.596930Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_train['Date'] = pd.to_datetime(df_train['Dates']).dt.date\n",
    "df_train['Heure'] = pd.to_datetime(df_train['Dates']).dt.time\n",
    "df_train['MonthofYear'] = pd.to_datetime(df_train['Date']).dt.month\n",
    "\n",
    "print(df_train)\n",
    "\n",
    "df_test['Date'] = pd.to_datetime(df_test['Dates']).dt.date\n",
    "df_test['Heure'] = pd.to_datetime(df_test['Dates']).dt.time\n",
    "df_test['MonthofYear'] = pd.to_datetime(df_test['Date']).dt.month\n",
    "\n",
    "print(df_test)\n",
    "\n",
    "df_train_patch = df_train[['Dates', 'Categorie', 'DayOfWeek', 'PdDistrict', 'Address', 'X', 'Y', 'Date', 'Heure', 'MonthofYear']]\n",
    "df_test_patch = df_test[['Dates', 'DayOfWeek', 'PdDistrict', 'Address', 'X', 'Y', 'Date', 'Heure', 'MonthofYear']]\n",
    "\n",
    "categorical_features = [col for col in df_train_patch.columns if df_train[col].dtype == 'object']\n",
    "encoder = OrdinalEncoder(cols=categorical_features).fit(df_train_patch)\n",
    "df_train_patch_2 = encoder.transform(df_train_patch)\n",
    "\n",
    "nb = 25000\n",
    "df_train_patch_sample = pd.concat([\n",
    "    df_train_patch_2[df_train_patch_2.Categorie == i].sample(min(nb, len(df_train_patch_2[df_train_patch_2.Categorie == i])), replace=True) \n",
    "    for i in range(4)\n",
    "])\n",
    "\n",
    "y = df_train_patch_sample.Categorie\n",
    "X = df_train_patch_sample.drop(['Categorie'], axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "# Decision Tree\n",
    "clf = tree.DecisionTreeClassifier().fit(X_train, y_train)\n",
    "acctree = clf.score(X_test, y_test) * 100\n",
    "print(f'Decision Tree Accuracy: {acctree:.2f}%')\n",
    "\n",
    "# Random Forest\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42).fit(X_train, y_train)\n",
    "accrf = accuracy_score(y_test, rf_classifier.predict(X_test)) * 100\n",
    "print(f'Random Forest Accuracy: {accrf:.2f}%')\n",
    "\n",
    "# K-Nearest Neighbors\n",
    "knn = KNeighborsClassifier(n_neighbors=2).fit(X_train, y_train)\n",
    "accknn = accuracy_score(y_test, knn.predict(X_test)) * 100\n",
    "print(f'KNN Accuracy: {accknn:.2f}%')\n",
    "\n",
    "print(\"Overall Accuracy\")\n",
    "print(f'Decision Tree: {acctree:.2f}%')\n",
    "print(f'Random Forest: {accrf:.2f}%')\n",
    "print(f'KNN: {accknn:.2f}%')\n",
    "glbacc = (acctree + accrf + accknn) / 3\n",
    "print(f'Global: {glbacc:.2f}%')\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning, message=\".*Downcasting object dtype arrays on .fillna.*\")\n",
    "\n",
    "new_data = {\n",
    "    \"Dates\": [\"2015-05-10 23:59:00\"],\n",
    "    \"DayOfWeek\": [\"Sunday\"],\n",
    "    \"PdDistrict\": [\"BAYVIEW\"],\n",
    "    \"Address\": [\"2000 Block of THOMAS AV\"],\n",
    "    \"X\": [-122.39958770418998],\n",
    "    \"Y\": [37.7350510103906],\n",
    "    \"Categorie\": [None]\n",
    "}\n",
    "\n",
    "new_df = pd.DataFrame(new_data)\n",
    "new_df_encoded = encoder.transform(new_df).drop(columns=['Categorie'])\n",
    "\n",
    "tree_prediction = clf.predict(new_df_encoded)\n",
    "rf_prediction = rf_classifier.predict(new_df_encoded)\n",
    "knn_prediction = knn.predict(new_df_encoded)\n",
    "\n",
    "predictions = [tuple(tree_prediction), tuple(rf_prediction), tuple(knn_prediction)]\n",
    "prediction_counts = Counter(predictions)\n",
    "most_common_prediction, count = prediction_counts.most_common(1)[0]\n",
    "\n",
    "if count == 1:\n",
    "    accuracies = {'tree': acctree, 'rf': accrf, 'knn': accknn}\n",
    "    most_accurate_model = max(accuracies, key=accuracies.get)\n",
    "    final_prediction = eval(f'{most_accurate_model}_prediction')\n",
    "else:\n",
    "    final_prediction = most_common_prediction\n",
    "\n",
    "final_prediction = int(final_prediction[0])\n",
    "print(f\"Final Prediction: {final_prediction}\")\n",
    "\n",
    "prediction_mapping = {\n",
    "    0: 'Arrestation / Poursuites',\n",
    "    1: 'Absence de poursuites / Refus / Cas particuliers',\n",
    "    2: 'Localisation / État de la personne',\n",
    "    3: 'Indépendant (NONE)'\n",
    "}\n",
    "\n",
    "final_prediction_text = prediction_mapping.get(final_prediction, \"Catégorie inconnue\")\n",
    "print(f\"Final Prediction: {final_prediction_text}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     Dates                Category  \\\n",
      "0      2015-05-13 23:53:00                WARRANTS   \n",
      "1      2015-05-13 23:53:00          OTHER OFFENSES   \n",
      "2      2015-05-13 23:33:00          OTHER OFFENSES   \n",
      "3      2015-05-13 23:30:00           LARCENY/THEFT   \n",
      "4      2015-05-13 23:30:00           LARCENY/THEFT   \n",
      "...                    ...                     ...   \n",
      "878044 2003-01-06 00:15:00                 ROBBERY   \n",
      "878045 2003-01-06 00:01:00           LARCENY/THEFT   \n",
      "878046 2003-01-06 00:01:00           LARCENY/THEFT   \n",
      "878047 2003-01-06 00:01:00               VANDALISM   \n",
      "878048 2003-01-06 00:01:00  FORGERY/COUNTERFEITING   \n",
      "\n",
      "                                         Descript  DayOfWeek PdDistrict  \\\n",
      "0                                  WARRANT ARREST  Wednesday   NORTHERN   \n",
      "1                        TRAFFIC VIOLATION ARREST  Wednesday   NORTHERN   \n",
      "2                        TRAFFIC VIOLATION ARREST  Wednesday   NORTHERN   \n",
      "3                    GRAND THEFT FROM LOCKED AUTO  Wednesday   NORTHERN   \n",
      "4                    GRAND THEFT FROM LOCKED AUTO  Wednesday       PARK   \n",
      "...                                           ...        ...        ...   \n",
      "878044           ROBBERY ON THE STREET WITH A GUN     Monday    TARAVAL   \n",
      "878045               GRAND THEFT FROM LOCKED AUTO     Monday  INGLESIDE   \n",
      "878046               GRAND THEFT FROM LOCKED AUTO     Monday   SOUTHERN   \n",
      "878047  MALICIOUS MISCHIEF, VANDALISM OF VEHICLES     Monday   SOUTHERN   \n",
      "878048                   CHECKS, FORGERY (FELONY)     Monday    BAYVIEW   \n",
      "\n",
      "            Resolution                     Address           X          Y  \\\n",
      "0       ARREST, BOOKED          OAK ST / LAGUNA ST -122.425892  37.774599   \n",
      "1       ARREST, BOOKED          OAK ST / LAGUNA ST -122.425892  37.774599   \n",
      "2       ARREST, BOOKED   VANNESS AV / GREENWICH ST -122.424363  37.800414   \n",
      "3                 NONE    1500 Block of LOMBARD ST -122.426995  37.800873   \n",
      "4                 NONE   100 Block of BRODERICK ST -122.438738  37.771541   \n",
      "...                ...                         ...         ...        ...   \n",
      "878044            NONE  FARALLONES ST / CAPITOL AV -122.459033  37.714056   \n",
      "878045            NONE        600 Block of EDNA ST -122.447364  37.731948   \n",
      "878046            NONE          5TH ST / FOLSOM ST -122.403390  37.780266   \n",
      "878047            NONE        TOWNSEND ST / 2ND ST -122.390531  37.780607   \n",
      "878048            NONE    1800 Block of NEWCOMB AV -122.394926  37.738212   \n",
      "\n",
      "                       Categorie        Date     Heure MonthOfYear  \\\n",
      "0       Arrestation / Poursuites  2015-05-13  23:53:00         May   \n",
      "1       Arrestation / Poursuites  2015-05-13  23:53:00         May   \n",
      "2       Arrestation / Poursuites  2015-05-13  23:33:00         May   \n",
      "3             Indépendant (NONE)  2015-05-13  23:30:00         May   \n",
      "4             Indépendant (NONE)  2015-05-13  23:30:00         May   \n",
      "...                          ...         ...       ...         ...   \n",
      "878044        Indépendant (NONE)  2003-01-06  00:15:00     January   \n",
      "878045        Indépendant (NONE)  2003-01-06  00:01:00     January   \n",
      "878046        Indépendant (NONE)  2003-01-06  00:01:00     January   \n",
      "878047        Indépendant (NONE)  2003-01-06  00:01:00     January   \n",
      "878048        Indépendant (NONE)  2003-01-06  00:01:00     January   \n",
      "\n",
      "        MonthofYear  \n",
      "0                 5  \n",
      "1                 5  \n",
      "2                 5  \n",
      "3                 5  \n",
      "4                 5  \n",
      "...             ...  \n",
      "878044            1  \n",
      "878045            1  \n",
      "878046            1  \n",
      "878047            1  \n",
      "878048            1  \n",
      "\n",
      "[878049 rows x 14 columns]\n",
      "            Id               Dates  DayOfWeek PdDistrict  \\\n",
      "0            0 2015-05-10 23:59:00     Sunday    BAYVIEW   \n",
      "1            1 2015-05-10 23:51:00     Sunday    BAYVIEW   \n",
      "2            2 2015-05-10 23:50:00     Sunday   NORTHERN   \n",
      "3            3 2015-05-10 23:45:00     Sunday  INGLESIDE   \n",
      "4            4 2015-05-10 23:45:00     Sunday  INGLESIDE   \n",
      "...        ...                 ...        ...        ...   \n",
      "884257  884257 2003-01-01 00:01:00  Wednesday    MISSION   \n",
      "884258  884258 2003-01-01 00:01:00  Wednesday   NORTHERN   \n",
      "884259  884259 2003-01-01 00:01:00  Wednesday  INGLESIDE   \n",
      "884260  884260 2003-01-01 00:01:00  Wednesday    BAYVIEW   \n",
      "884261  884261 2003-01-01 00:01:00  Wednesday    TARAVAL   \n",
      "\n",
      "                            Address           X          Y        Date  \\\n",
      "0           2000 Block of THOMAS AV -122.399588  37.735051  2015-05-10   \n",
      "1                3RD ST / REVERE AV -122.391523  37.732432  2015-05-10   \n",
      "2            2000 Block of GOUGH ST -122.426002  37.792212  2015-05-10   \n",
      "3          4700 Block of MISSION ST -122.437394  37.721412  2015-05-10   \n",
      "4          4700 Block of MISSION ST -122.437394  37.721412  2015-05-10   \n",
      "...                             ...         ...        ...         ...   \n",
      "884257      2600 Block of BRYANT ST -122.408983  37.751987  2003-01-01   \n",
      "884258  1900 Block of WASHINGTON ST -122.425342  37.792681  2003-01-01   \n",
      "884259     5500 Block of MISSION ST -122.445418  37.712075  2003-01-01   \n",
      "884260      1500 Block of HUDSON AV -122.387394  37.739479  2003-01-01   \n",
      "884261       1500 Block of SLOAT BL -122.489714  37.733950  2003-01-01   \n",
      "\n",
      "           Heure MonthOfYear  MonthofYear  \n",
      "0       23:59:00         May            5  \n",
      "1       23:51:00         May            5  \n",
      "2       23:50:00         May            5  \n",
      "3       23:45:00         May            5  \n",
      "4       23:45:00         May            5  \n",
      "...          ...         ...          ...  \n",
      "884257  00:01:00     January            1  \n",
      "884258  00:01:00     January            1  \n",
      "884259  00:01:00     January            1  \n",
      "884260  00:01:00     January            1  \n",
      "884261  00:01:00     January            1  \n",
      "\n",
      "[884262 rows x 11 columns]\n"
     ]
    },
    {
     "ename": "DTypePromotionError",
     "evalue": "The DType <class 'numpy.dtypes.DateTime64DType'> could not be promoted by <class 'numpy.dtypes.Float64DType'>. This means that no common DType exists for the given inputs. For example they cannot be stored in a single array unless the dtype is `object`. The full list of DTypes is: (<class 'numpy.dtypes.DateTime64DType'>, <class 'numpy.dtypes.Int64DType'>, <class 'numpy.dtypes.Int64DType'>, <class 'numpy.dtypes.Int64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Int64DType'>, <class 'numpy.dtypes.Int64DType'>, <class 'numpy.dtypes.Int32DType'>)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mDTypePromotionError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[43], line 31\u001B[0m\n\u001B[0;32m     28\u001B[0m X_train, X_test, y_train, y_test \u001B[38;5;241m=\u001B[39m train_test_split(X, y, test_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.33\u001B[39m, random_state\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m42\u001B[39m)\n\u001B[0;32m     30\u001B[0m \u001B[38;5;66;03m# Decision Tree\u001B[39;00m\n\u001B[1;32m---> 31\u001B[0m clf \u001B[38;5;241m=\u001B[39m \u001B[43mtree\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mDecisionTreeClassifier\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     32\u001B[0m acctree \u001B[38;5;241m=\u001B[39m clf\u001B[38;5;241m.\u001B[39mscore(X_test, y_test) \u001B[38;5;241m*\u001B[39m \u001B[38;5;241m100\u001B[39m\n\u001B[0;32m     33\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mDecision Tree Accuracy: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00macctree\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m.2f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m%\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\base.py:1473\u001B[0m, in \u001B[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001B[1;34m(estimator, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1466\u001B[0m     estimator\u001B[38;5;241m.\u001B[39m_validate_params()\n\u001B[0;32m   1468\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[0;32m   1469\u001B[0m     skip_parameter_validation\u001B[38;5;241m=\u001B[39m(\n\u001B[0;32m   1470\u001B[0m         prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[0;32m   1471\u001B[0m     )\n\u001B[0;32m   1472\u001B[0m ):\n\u001B[1;32m-> 1473\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m fit_method(estimator, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\tree\\_classes.py:1009\u001B[0m, in \u001B[0;36mDecisionTreeClassifier.fit\u001B[1;34m(self, X, y, sample_weight, check_input)\u001B[0m\n\u001B[0;32m    978\u001B[0m \u001B[38;5;129m@_fit_context\u001B[39m(prefer_skip_nested_validation\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m    979\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfit\u001B[39m(\u001B[38;5;28mself\u001B[39m, X, y, sample_weight\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, check_input\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m):\n\u001B[0;32m    980\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Build a decision tree classifier from the training set (X, y).\u001B[39;00m\n\u001B[0;32m    981\u001B[0m \n\u001B[0;32m    982\u001B[0m \u001B[38;5;124;03m    Parameters\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1006\u001B[0m \u001B[38;5;124;03m        Fitted estimator.\u001B[39;00m\n\u001B[0;32m   1007\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m-> 1009\u001B[0m     \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_fit\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1010\u001B[0m \u001B[43m        \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1011\u001B[0m \u001B[43m        \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1012\u001B[0m \u001B[43m        \u001B[49m\u001B[43msample_weight\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msample_weight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1013\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcheck_input\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcheck_input\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1014\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1015\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\tree\\_classes.py:252\u001B[0m, in \u001B[0;36mBaseDecisionTree._fit\u001B[1;34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001B[0m\n\u001B[0;32m    248\u001B[0m check_X_params \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mdict\u001B[39m(\n\u001B[0;32m    249\u001B[0m     dtype\u001B[38;5;241m=\u001B[39mDTYPE, accept_sparse\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcsc\u001B[39m\u001B[38;5;124m\"\u001B[39m, force_all_finite\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[0;32m    250\u001B[0m )\n\u001B[0;32m    251\u001B[0m check_y_params \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mdict\u001B[39m(ensure_2d\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m, dtype\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[1;32m--> 252\u001B[0m X, y \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_validate_data\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    253\u001B[0m \u001B[43m    \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalidate_separately\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcheck_X_params\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcheck_y_params\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    254\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    256\u001B[0m missing_values_in_feature_mask \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m    257\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compute_missing_values_in_feature_mask(X)\n\u001B[0;32m    258\u001B[0m )\n\u001B[0;32m    259\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m issparse(X):\n",
      "File \u001B[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\base.py:645\u001B[0m, in \u001B[0;36mBaseEstimator._validate_data\u001B[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001B[0m\n\u001B[0;32m    643\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mestimator\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m check_X_params:\n\u001B[0;32m    644\u001B[0m     check_X_params \u001B[38;5;241m=\u001B[39m {\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mdefault_check_params, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mcheck_X_params}\n\u001B[1;32m--> 645\u001B[0m X \u001B[38;5;241m=\u001B[39m check_array(X, input_name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mX\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mcheck_X_params)\n\u001B[0;32m    646\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mestimator\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m check_y_params:\n\u001B[0;32m    647\u001B[0m     check_y_params \u001B[38;5;241m=\u001B[39m {\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mdefault_check_params, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mcheck_y_params}\n",
      "File \u001B[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\utils\\validation.py:887\u001B[0m, in \u001B[0;36mcheck_array\u001B[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001B[0m\n\u001B[0;32m    883\u001B[0m pandas_requires_conversion \u001B[38;5;241m=\u001B[39m \u001B[38;5;28many\u001B[39m(\n\u001B[0;32m    884\u001B[0m     _pandas_dtype_needs_early_conversion(i) \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m dtypes_orig\n\u001B[0;32m    885\u001B[0m )\n\u001B[0;32m    886\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mall\u001B[39m(\u001B[38;5;28misinstance\u001B[39m(dtype_iter, np\u001B[38;5;241m.\u001B[39mdtype) \u001B[38;5;28;01mfor\u001B[39;00m dtype_iter \u001B[38;5;129;01min\u001B[39;00m dtypes_orig):\n\u001B[1;32m--> 887\u001B[0m     dtype_orig \u001B[38;5;241m=\u001B[39m \u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mresult_type\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mdtypes_orig\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    888\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m pandas_requires_conversion \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28many\u001B[39m(d \u001B[38;5;241m==\u001B[39m \u001B[38;5;28mobject\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m d \u001B[38;5;129;01min\u001B[39;00m dtypes_orig):\n\u001B[0;32m    889\u001B[0m     \u001B[38;5;66;03m# Force object if any of the dtypes is an object\u001B[39;00m\n\u001B[0;32m    890\u001B[0m     dtype_orig \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mobject\u001B[39m\n",
      "\u001B[1;31mDTypePromotionError\u001B[0m: The DType <class 'numpy.dtypes.DateTime64DType'> could not be promoted by <class 'numpy.dtypes.Float64DType'>. This means that no common DType exists for the given inputs. For example they cannot be stored in a single array unless the dtype is `object`. The full list of DTypes is: (<class 'numpy.dtypes.DateTime64DType'>, <class 'numpy.dtypes.Int64DType'>, <class 'numpy.dtypes.Int64DType'>, <class 'numpy.dtypes.Int64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Int64DType'>, <class 'numpy.dtypes.Int64DType'>, <class 'numpy.dtypes.Int32DType'>)"
     ]
    }
   ],
   "execution_count": 43
  }
 ]
}
